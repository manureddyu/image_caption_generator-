{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a72cb19-eaef-4fb3-ae20-773858e5dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\manuj\\anaconda3\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5796bf3c-66ae-47ca-b00e-df4c7a74a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\manuj\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\manuj\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\manuj\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b81ccf3-ec33-4ea9-854b-6435e658e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\manuj\\anaconda3\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8b095c-8488-47c0-85b3-f4b62d7c4308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: a man sitting at a table with a cat\n"
     ]
    }
   ],
   "source": [
    "#this is for only one image\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Load an image\n",
    "image_path = \"E:\\\\cat.jpg\"  # Change this to any image\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Generate a caption\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs)\n",
    "caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4da2434-98fd-4be4-b4b2-de854af47e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\manuj\\anaconda3\\lib\\site-packages (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install colorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb78f1a-3868-4c60-9622-ca524963bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.1/55.1 kB ? eta 0:00:00\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.4/133.4 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.0/65.0 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.1/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.6/53.6 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17458 sha256=92ef9a8c557cd1e191718ebd661c67ce4e2cbd4de63c66381acbf8148f2de53c\n",
      "  Stored in directory: c:\\users\\manuj\\appdata\\local\\pip\\cache\\wheels\\39\\17\\6f\\66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd6f376c-220f-474b-8e49-d6a7a79148b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¼ï¸ eight.jpg\n",
      "ğŸŒ English: a snowy road in the mountains\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®®à®²à¯ˆà®•à®³à®¿à®²à¯ à®’à®°à¯ à®ªà®©à®¿ à®šà®¾à®²à¯ˆ\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²ªà²°à³à²µà²¤à²—à²³à²²à³à²²à²¿ à²¹à²¿à²®à²­à²°à²¿à²¤ à²°à²¸à³à²¤à³†\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°ªà°°à±à°µà°¤à°¾à°²à°²à±‹ à°®à°‚à°šà±à°¤à±‹ à°•à±‚à°¡à°¿à°¨ à°°à°¹à°¦à°¾à°°à°¿\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´ªàµ¼à´µà´¤à´™àµà´™à´³à´¿à´²àµ† à´®à´àµà´àµà´µàµ€à´´àµà´šà´¯àµà´³àµà´³ à´±àµ‹à´¡àµ\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤ªà¤¹à¤¾à¤¡à¤¼à¥‹à¤‚ à¤®à¥‡à¤‚ à¤à¤• à¤¬à¤°à¥à¤«à¥€à¤²à¥€ à¤¸à¤¡à¤¼à¤•\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ five.jpg\n",
      "ğŸŒ English: a bird sitting on a wall in the rain\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®®à®´à¯ˆà®¯à®¿à®²à¯ à®’à®°à¯ à®šà¯à®µà®°à®¿à®²à¯ à®…à®®à®°à¯à®¨à¯à®¤à®¿à®°à¯à®•à¯à®•à¯à®®à¯ à®ªà®±à®µà¯ˆ\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²®à²³à³†à²¯à²²à³à²²à²¿ à²—à³‹à²¡à³†à²¯ à²®à³‡à²²à³† à²•à³à²³à²¿à²¤à²¿à²¦à³à²¦ à²¹à²•à³à²•à²¿\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°µà°°à±à°·à°‚à°²à±‹ à°—à±‹à°¡à°ªà±ˆ à°•à±‚à°°à±à°šà±à°¨à±à°¨ à°ªà°•à±à°·à°¿\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´®à´´à´¯à´¿àµ½ à´’à´°àµ à´®à´¤à´¿àµ½ à´‡à´°à´¿à´•àµà´•àµà´¨àµà´¨ à´ªà´•àµà´·à´¿\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤¬à¤¾à¤°à¤¿à¤¶ à¤®à¥‡à¤‚ à¤à¤• à¤¦à¥€à¤µà¤¾à¤° à¤ªà¤° à¤¬à¥ˆà¤ à¤¾ à¤à¤• à¤ªà¤•à¥à¤·à¥€\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ four.jpg\n",
      "ğŸŒ English: a couple sitting on a bench looking out at the ocean\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®’à®°à¯ à®ªà¯†à®à¯à®šà®¿à®²à¯ à®‰à®Ÿà¯à®•à®¾à®°à¯à®¨à¯à®¤à®¿à®°à¯à®•à¯à®•à¯à®®à¯ à®’à®°à¯ à®œà¯‹à®Ÿà®¿ à®•à®Ÿà®²à¯à®•à¯à®•à¯ à®µà¯†à®³à®¿à®¯à¯‡\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²¦à²‚à²ªà²¤à²¿à²—à²³à³ à²¸à²¾à²—à²°à²µà²¨à³à²¨à³ à²¨à³‹à²¡à³à²¤à³à²¤à²¿à²°à³à²µ à²¬à³†à²‚à²šà³ à²®à³‡à²²à³† à²•à³à²³à²¿à²¤à²¿à²¦à³à²¦à²¾à²°à³†\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°’à°• à°œà°‚à°Ÿ à°¸à°®à±à°¦à±à°°à°‚ à°µà±ˆà°ªà± à°šà±‚à°¸à±à°¤à±à°¨à±à°¨ à°¬à±†à°‚à°šà± à°®à±€à°¦ à°•à±‚à°°à±à°šà±à°¨à±à°¨à°¾à°°à±\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´¸à´®àµà´¦àµà´°à´¤àµà´¤à´¿àµ½ à´¨àµ‹à´•àµà´•àµà´®àµà´ªàµ‹àµ¾ à´’à´°àµ à´¬àµ†à´àµà´šà´¿àµ½ à´‡à´°à´¿à´•àµà´•àµà´¨àµà´¨ à´¦à´®àµà´ªà´¤à´¿à´•àµ¾\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤à¤• à¤¬à¥‡à¤‚à¤š à¤ªà¤° à¤¬à¥ˆà¤ à¥‡ à¤à¤• à¤œà¥‹à¤¡à¤¼à¥‡ à¤¸à¤®à¥à¤¦à¥à¤° à¤®à¥‡à¤‚ à¤¬à¤¾à¤¹à¤° à¤¦à¥‡à¤– à¤°à¤¹à¥‡ à¤¹à¥ˆà¤‚\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ nine.jpg\n",
      "ğŸŒ English: a man walking up a path in the mountains\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®®à®²à¯ˆà®•à®³à®¿à®²à¯ à®’à®°à¯ à®ªà®¾à®¤à¯ˆà®¯à®¿à®²à¯ à®¨à®Ÿà®¨à¯à®¤à¯ à®šà¯†à®²à¯à®²à¯à®®à¯ à®’à®°à¯ à®®à®©à®¿à®¤à®©à¯\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²ªà²°à³à²µà²¤à²—à²³à²²à³à²²à²¿ à²’à²‚à²¦à³ à²¹à²¾à²¦à²¿à²¯à²²à³à²²à²¿ à²¨à²¡à³†à²¯à³à²µ à²µà³à²¯à²•à³à²¤à²¿\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°’à°• à°µà±à°¯à°•à±à°¤à°¿ à°ªà°°à±à°µà°¤à°¾à°²à°²à±‹ à°’à°• à°®à°¾à°°à±à°—à°‚ à°ªà±ˆà°•à°¿ à°¨à°¡à±à°¸à±à°¤à±à°¨à±à°¨à°¾à°¡à±\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´’à´°àµ à´®à´¨àµà´·àµà´¯àµ» à´ªàµ¼à´µà´¤à´™àµà´™à´³à´¿àµ½ à´’à´°àµ à´ªà´¾à´¤à´¯à´¿à´²àµ‚à´Ÿàµ† à´¨à´Ÿà´•àµà´•àµà´¨àµà´¨àµ\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤à¤• à¤†à¤¦à¤®à¥€ à¤ªà¤¹à¤¾à¤¡à¤¼à¥‹à¤‚ à¤®à¥‡à¤‚ à¤à¤• à¤°à¤¾à¤¸à¥à¤¤à¤¾ à¤šà¤² à¤°à¤¹à¤¾ à¤¹à¥ˆ\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ one.jpg\n",
      "ğŸŒ English: a bird perched on a tree stump\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®’à®°à¯ à®®à®°à®¤à¯à®¤à®¿à®©à¯ à®¸à¯à®Ÿà®®à¯à®ªà®¿à®²à¯ à®’à®°à¯ à®ªà®±à®µà¯ˆ\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²®à²°à²¦ à²¸à³à²Ÿà²‚à²ªà³ à²®à³‡à²²à³† à²’à²‚à²¦à³ à²¹à²•à³à²•à²¿\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°šà±†à°Ÿà±à°Ÿà± à°¸à±à°Ÿà°‚à°ªà± à°®à±€à°¦ à°’à°• à°ªà°•à±à°·à°¿\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´’à´°àµ à´®à´°à´¤àµà´¤à´¿àµ½ à´’à´°àµ à´ªà´•àµà´·à´¿\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤à¤• à¤ªà¤•à¥à¤·à¥€ à¤à¤• à¤ªà¥‡à¤¡à¤¼ à¤•à¥‡ à¤¸à¥à¤Ÿà¤‚à¤ª à¤ªà¤° à¤¬à¥ˆà¤  à¤—à¤¯à¤¾\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ seven.jpg\n",
      "ğŸŒ English: a bright orange sunset over the ocean\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®•à®Ÿà®²à¯à®•à¯à®•à¯ à®®à¯‡à®²à¯ à®’à®°à¯ à®ªà®¿à®°à®•à®¾à®šà®®à®¾à®© à®†à®°à®à¯à®šà¯ à®šà¯‚à®°à®¿à®¯ à®…à®¸à¯à®¤à®®à®©à®®à¯\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²¸à²®à³à²¦à³à²°à²¦ à²®à³‡à²²à³† à²ªà³à²°à²•à²¾à²¶à²®à²¾à²¨à²µà²¾à²¦ à²•à²¿à²¤à³à²¤à²³à³† à²¸à³‚à²°à³à²¯à²¾à²¸à³à²¤\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°¸à°®à±à°¦à±à°°à°‚ à°®à±€à°¦ à°ªà±à°°à°•à°¾à°¶à°µà°‚à°¤à°®à±ˆà°¨ à°¨à°¾à°°à°¿à°‚à°œ à°¸à±‚à°°à±à°¯à°¾à°¸à±à°¤à°®à°¯à°‚\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´¸à´®àµà´¦àµà´°à´¤àµà´¤à´¿à´¨àµ à´®àµà´•à´³à´¿àµ½ à´’à´°àµ à´¤à´¿à´³à´•àµà´•à´®àµà´³àµà´³ à´“à´±à´àµà´šàµ à´¸àµ‚à´°àµà´¯à´¾à´¸àµà´¤à´®à´¯à´‚\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤¸à¤®à¥à¤¦à¥à¤° à¤•à¥‡ à¤Šà¤ªà¤° à¤à¤• à¤‰à¤œà¥à¤œà¥à¤µà¤² à¤¨à¤¾à¤°à¤‚à¤—à¥€ à¤¸à¥‚à¤°à¥à¤¯à¤¾à¤¸à¥à¤¤\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ six.jpg\n",
      "ğŸŒ English: a woman sitting in a chair in a living room\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®’à®°à¯ à®µà®¾à®´à¯à®•à¯à®•à¯ˆ à®…à®±à¯ˆà®¯à®¿à®²à¯ à®¨à®¾à®±à¯à®•à®¾à®²à®¿à®¯à®¿à®²à¯ à®…à®®à®°à¯à®¨à¯à®¤à®¿à®°à¯à®•à¯à®•à¯à®®à¯ à®’à®°à¯ à®ªà¯†à®£à¯\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²µà²¾à²¸à²¦ à²•à³‹à²£à³†à²¯à²²à³à²²à²¿ à²•à³à²°à³à²šà²¿à²¯à²²à³à²²à²¿ à²•à³à²³à²¿à²¤ à²®à²¹à²¿à²³à³†\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°’à°• à°®à°¹à°¿à°³ à°—à°¦à°¿à°²à±‹ à°•à±à°°à±à°šà±€à°²à±‹ à°•à±‚à°°à±à°šà±à°¨à°¿\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´’à´°àµ à´¸àµà´µàµ€à´•à´°à´£à´®àµà´±à´¿à´¯à´¿àµ½ à´’à´°àµ à´µà´¨à´¿à´¤ à´’à´°àµ à´¸àµà´¤àµà´°àµ€\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤²à¤¿à¤µà¤¿à¤‚à¤— à¤°à¥‚à¤® à¤®à¥‡à¤‚ à¤à¤• à¤•à¥à¤°à¥à¤¸à¥€ à¤ªà¤° à¤¬à¥ˆà¤ à¥€ à¤à¤• à¤®à¤¹à¤¿à¤²à¤¾\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ ten.jpg\n",
      "ğŸŒ English: a cup with a flower in it\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®…à®¤à®¿à®²à¯ à®’à®°à¯ à®ªà¯‚à®µà¯à®Ÿà®©à¯ à®’à®°à¯ à®•à®ªà¯\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²…à²¦à²°à²²à³à²²à²¿ à²¹à³‚à²µà²¿à²¨à³Šà²‚à²¦à²¿à²—à³† à²’à²‚à²¦à³ à²•à²ªà³\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°¦à°¾à°¨à°¿à°²à±‹ à°’à°• à°ªà±à°µà±à°µà±à°¤à±‹ à°’à°• à°•à°ªà±à°ªà±\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´…à´¤à´¿àµ½ à´’à´°àµ à´ªàµà´·àµà´ªà´®àµà´³àµà´³ à´’à´°àµ à´•à´ªàµà´ªàµ\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤‡à¤¸à¤®à¥‡à¤‚ à¤à¤• à¤«à¥‚à¤² à¤•à¥‡ à¤¸à¤¾à¤¥ à¤à¤• à¤•à¤ª\n",
      "--------------------------------------------------\n",
      "ğŸ–¼ï¸ three.jpg\n",
      "ğŸŒ English: two swans swimming in the water\n",
      "ğŸŒ Tamil ğŸ‡®ğŸ‡³: à®‡à®°à®£à¯à®Ÿà¯ à®¸à¯à®µà®¾à®©à¯à®¸à¯ à®¤à®£à¯à®£à¯€à®°à®¿à®²à¯ à®¨à¯€à®¨à¯à®¤à¯à®•à®¿à®±à®¤à¯\n",
      "ğŸŒ Kannada ğŸ‡®ğŸ‡³: à²à²°à²¡à³ à²¹à²‚à²¸à²—à²³à³ à²¨à³€à²°à²¿à²¨à²²à³à²²à²¿ à²ˆà²œà³à²¤à³à²¤à²¿à²µà³†\n",
      "ğŸŒ Telugu ğŸ‡®ğŸ‡³: à°°à±†à°‚à°¡à± à°¹à°‚à°¸à°²à± à°¨à±€à°Ÿà°¿à°²à±‹ à°ˆà°¤ à°•à±Šà°¡à±à°¤à±à°¨à±à°¨à°¾à°¯à°¿\n",
      "ğŸŒ Malayalam ğŸ‡®ğŸ‡³: à´µàµ†à´³àµà´³à´¤àµà´¤à´¿àµ½ à´¨àµ€à´¨àµà´¤àµ½\n",
      "ğŸŒ Hindi ğŸ‡®ğŸ‡³: à¤¦à¥‹ à¤¹à¤‚à¤¸ à¤ªà¤¾à¤¨à¥€ à¤®à¥‡à¤‚ à¤¤à¥ˆà¤°à¤¤à¥‡ à¤¹à¥à¤\n",
      "--------------------------------------------------\n",
      "\n",
      "âœ… Captions saved in **captions_combined.txt**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "from googletrans import Translator\n",
    "\n",
    "# Load BLIP Model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Initialize Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Define paths\n",
    "image_folder = \"E:\\\\images\"   # Folder with images\n",
    "video_path = \"E:\\\\videos.mp4\"  # Path to video\n",
    "frames_folder = \"E:\\\\videos\\\\frames\"\n",
    "output_file = \"captions_combined.txt\"\n",
    "\n",
    "# Ensure folders exist\n",
    "os.makedirs(frames_folder, exist_ok=True)\n",
    "\n",
    "# Function to generate captions for an image\n",
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# Function to translate captions into multiple languages\n",
    "def translate_caption(caption):\n",
    "    languages = {\n",
    "        \"ta\": \"Tamil ğŸ‡®ğŸ‡³\", \"kn\": \"Kannada ğŸ‡®ğŸ‡³\", \"te\": \"Telugu ğŸ‡®ğŸ‡³\", \n",
    "        \"ml\": \"Malayalam ğŸ‡®ğŸ‡³\", \"hi\": \"Hindi ğŸ‡®ğŸ‡³\"\n",
    "    }\n",
    "    translated_captions = { \"English\": caption }\n",
    "    \n",
    "    for lang_code, lang_name in languages.items():\n",
    "        translated_captions[lang_name] = translator.translate(caption, dest=lang_code).text\n",
    "    \n",
    "    return translated_captions\n",
    "\n",
    "# Store captions\n",
    "captions_list = []\n",
    "\n",
    "### **ğŸ“¸ Process Images**\n",
    "for image_name in os.listdir(image_folder):\n",
    "    if image_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        caption = generate_caption(image_path)\n",
    "        translated_captions = translate_caption(caption)\n",
    "\n",
    "        # Save captions\n",
    "        captions_list.append(f\"ğŸ–¼ï¸ {image_name}\")\n",
    "        for lang, trans_caption in translated_captions.items():\n",
    "            captions_list.append(f\"ğŸŒ {lang}: {trans_caption}\")\n",
    "        captions_list.append(\"-\" * 50)\n",
    "\n",
    "### **ğŸ¥ Process Video Frames**\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get FPS\n",
    "frame_interval = 5 * fps  # Capture every 5 seconds\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract frame at intervals\n",
    "    if frame_count % frame_interval == 0:\n",
    "        frame_filename = os.path.join(frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "        caption = generate_caption(frame_filename)\n",
    "        translated_captions = translate_caption(caption)\n",
    "\n",
    "        # Convert frame timestamp\n",
    "        time_stamp = frame_count // fps\n",
    "        minutes, seconds = divmod(time_stamp, 60)\n",
    "        time_format = f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "        # Save captions\n",
    "        captions_list.append(f\"ğŸ•’ [{time_format}]\")\n",
    "        for lang, trans_caption in translated_captions.items():\n",
    "            captions_list.append(f\"ğŸŒ {lang}: {trans_caption}\")\n",
    "        captions_list.append(\"-\" * 50)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Save captions to file and print in terminal\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for caption in captions_list:\n",
    "        print(caption)  # âœ… Print in terminal\n",
    "        f.write(caption + \"\\n\")\n",
    "\n",
    "print(f\"\\nâœ… Captions saved in **{output_file}**\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6017eeb5-d00d-4cf9-abff-754c758ee97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select input type:\n",
      "1ï¸âƒ£ Images\n",
      "2ï¸âƒ£ Videos\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1/2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a language:\n",
      "1. English\n",
      "2. Tamil\n",
      "3. Kannada\n",
      "4. Telugu\n",
      "5. Malayalam\n",
      "6. Hindi\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your language choice:  1,3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Processing Video...\n",
      "\n",
      "\n",
      "âœ… Captions saved in **captions_combined.txt**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load BLIP model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# User selects content type\n",
    "print(\"\\nSelect input type:\")\n",
    "print(\"1ï¸âƒ£ Images\")\n",
    "print(\"2ï¸âƒ£ Videos\")\n",
    "choice = input(\"Enter your choice (1/2): \")\n",
    "\n",
    "# User selects language\n",
    "languages = {\n",
    "    \"1\": \"English\",\n",
    "    \"2\": \"Tamil\",\n",
    "    \"3\": \"Kannada\",\n",
    "    \"4\": \"Telugu\",\n",
    "    \"5\": \"Malayalam\",\n",
    "    \"6\": \"Hindi\",\n",
    "}\n",
    "print(\"\\nSelect a language:\")\n",
    "for key, lang in languages.items():\n",
    "    print(f\"{key}. {lang}\")\n",
    "\n",
    "lang_choice = input(\"\\nEnter your language choice: \")\n",
    "\n",
    "# Set up paths\n",
    "image_folder = \"images\"\n",
    "video_folder = \"videos\"\n",
    "frames_folder = \"frames\"\n",
    "output_file = \"captions_combined.txt\"\n",
    "os.makedirs(frames_folder, exist_ok=True)  # Ensure frames folder exists\n",
    "\n",
    "captions_list = []\n",
    "\n",
    "# Process images\n",
    "if choice == \"1\":\n",
    "    print(\"\\nğŸ”¹ Processing Images...\\n\")\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        if image_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            try:\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                inputs = processor(image, return_tensors=\"pt\")\n",
    "                output = model.generate(**inputs)\n",
    "                caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "                captions_list.append(f\"{image_name}: {caption}\")\n",
    "                print(f\"âœ… {image_name}: {caption}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ Error processing {image_name}: {e}\")\n",
    "\n",
    "# Process videos (Extract frames every 5 seconds)\n",
    "elif choice == \"2\":\n",
    "    print(\"\\nğŸ”¹ Processing Video...\\n\")\n",
    "    for video_name in os.listdir(video_folder):\n",
    "        if video_name.lower().endswith((\".mp4\", \".avi\", \".mov\", \".mkv\")):\n",
    "            video_path = os.path.join(video_folder, video_name)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "            frame_interval = 5 * fps  # Capture every 5 seconds\n",
    "\n",
    "            frame_count = 0\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                if frame_count % frame_interval == 0:\n",
    "                    frame_filename = os.path.join(frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "                    cv2.imwrite(frame_filename, frame)\n",
    "                    print(f\"ğŸ“¸ Extracted Frame: {frame_filename}\")\n",
    "\n",
    "                    # Generate caption for frame\n",
    "                    try:\n",
    "                        image = Image.open(frame_filename).convert(\"RGB\")\n",
    "                        inputs = processor(image, return_tensors=\"pt\")\n",
    "                        output = model.generate(**inputs)\n",
    "                        caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "                        captions_list.append(f\"{frame_filename}: {caption}\")\n",
    "                        print(f\"âœ… Caption: {caption}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Error processing {frame_filename}: {e}\")\n",
    "\n",
    "                frame_count += 1\n",
    "            cap.release()\n",
    "\n",
    "# Save captions\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(captions_list))\n",
    "\n",
    "print(f\"\\nâœ… Captions saved in **{output_file}**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9541b81-e7f4-465e-8543-ab5b6ae5a33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BLIP model...\n",
      "Model loaded successfully!\n",
      "âœ… Found images folder: E:\\images\n",
      "ğŸ“‚ Found 9 images: ['eight.jpg', 'five.jpg', 'four.jpg', 'nine.jpg', 'one.jpg', 'seven.jpg', 'six.jpg', 'ten.jpg', 'three.jpg']\n",
      "ğŸ–¼ Processing image: E:\\images\\eight.jpg\n",
      "âœ… Caption: a snowy road in the mountains\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# Load model\n",
    "print(\"Loading BLIP model...\")\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Check images folder\n",
    "image_folder = \"E:\\\\images\"\n",
    "if not os.path.exists(image_folder):\n",
    "    print(f\"Error: Folder '{image_folder}' not found!\")\n",
    "else:\n",
    "    print(f\"âœ… Found images folder: {image_folder}\")\n",
    "\n",
    "# List available images\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "print(f\"ğŸ“‚ Found {len(image_files)} images: {image_files}\")\n",
    "\n",
    "# Process first image for testing\n",
    "if image_files:\n",
    "    image_path = os.path.join(image_folder, image_files[0])\n",
    "    print(f\"ğŸ–¼ Processing image: {image_path}\")\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "    print(f\"âœ… Caption: {caption}\")\n",
    "else:\n",
    "    print(\"âŒ No images found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e07763b-789c-4986-91a0-808f4b6e02ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Captures', 'desktop.ini', 'practice1.ipynb', 'Screen Recordings', 'Shortcut to Videos (OneDrive - Personal).lnk']\n",
      "Error: Cannot open video file!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"videos\"))  # Should list your video files\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"E:\\\\videos/sample.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file!\")\n",
    "else:\n",
    "    print(\"Video opened successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd79d0-bb8d-4541-a67a-64f2b17b46a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
