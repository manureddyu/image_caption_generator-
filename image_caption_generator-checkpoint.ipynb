{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a72cb19-eaef-4fb3-ae20-773858e5dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\manuj\\anaconda3\\lib\\site-packages (4.50.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5796bf3c-66ae-47ca-b00e-df4c7a74a085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\manuj\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\manuj\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\manuj\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (4.13.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b81ccf3-ec33-4ea9-854b-6435e658e00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in c:\\users\\manuj\\anaconda3\\lib\\site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (8.20.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from ipython>=6.1.0->ipywidgets) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: executing in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from asttokens->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade ipywidgets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba8b095c-8488-47c0-85b3-f4b62d7c4308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Caption: a man sitting at a table with a cat\n"
     ]
    }
   ],
   "source": [
    "#this is for only one image\n",
    "\n",
    "\n",
    "\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# Load the model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Load an image\n",
    "image_path = \"E:\\\\cat.jpg\"  # Change this to any image\n",
    "image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "# Generate a caption\n",
    "inputs = processor(image, return_tensors=\"pt\")\n",
    "output = model.generate(**inputs)\n",
    "caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(\"Generated Caption:\", caption)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4da2434-98fd-4be4-b4b2-de854af47e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\manuj\\anaconda3\\lib\\site-packages (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install colorama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bb78f1a-3868-4c60-9622-ca524963bbd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting googletrans==4.0.0-rc1\n",
      "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
      "  Downloading httpx-0.13.3-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2025.1.31)\n",
      "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hstspreload-2025.1.1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\manuj\\anaconda3\\lib\\site-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.0)\n",
      "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading httpcore-0.9.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h11-0.9.0-py2.py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading h2-3.2.0-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
      "  Downloading hpack-3.0.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
      "   ---------------------------------------- 0.0/55.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 55.1/55.1 kB ? eta 0:00:00\n",
      "Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 133.4/133.4 kB 4.0 MB/s eta 0:00:00\n",
      "Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
      "   ---------------------------------------- 0.0/42.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 42.6/42.6 kB 2.0 MB/s eta 0:00:00\n",
      "Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "   ---------------------------------------- 0.0/58.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 58.8/58.8 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
      "   ---------------------------------------- 0.0/65.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 65.0/65.0 kB 3.4 MB/s eta 0:00:00\n",
      "Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
      "Downloading hstspreload-2025.1.1-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.3 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.4/1.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.6/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.8/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.1/1.3 MB 4.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.3/1.3 MB 4.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.3/1.3 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
      "   ---------------------------------------- 0.0/53.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 53.6/53.6 kB 2.7 MB/s eta 0:00:00\n",
      "Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
      "Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
      "Building wheels for collected packages: googletrans\n",
      "  Building wheel for googletrans (setup.py): started\n",
      "  Building wheel for googletrans (setup.py): finished with status 'done'\n",
      "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17458 sha256=92ef9a8c557cd1e191718ebd661c67ce4e2cbd4de63c66381acbf8148f2de53c\n",
      "  Stored in directory: c:\\users\\manuj\\appdata\\local\\pip\\cache\\wheels\\39\\17\\6f\\66a045ea3d168826074691b4b787b8f324d3f646d755443fda\n",
      "Successfully built googletrans\n",
      "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 4.0.0\n",
      "    Uninstalling chardet-4.0.0:\n",
      "      Successfully uninstalled chardet-4.0.0\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.4\n",
      "    Uninstalling idna-3.4:\n",
      "      Successfully uninstalled idna-3.4\n",
      "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2025.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install googletrans==4.0.0-rc1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd6f376c-220f-474b-8e49-d6a7a79148b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🖼️ eight.jpg\n",
      "🌍 English: a snowy road in the mountains\n",
      "🌍 Tamil 🇮🇳: மலைகளில் ஒரு பனி சாலை\n",
      "🌍 Kannada 🇮🇳: ಪರ್ವತಗಳಲ್ಲಿ ಹಿಮಭರಿತ ರಸ್ತೆ\n",
      "🌍 Telugu 🇮🇳: పర్వతాలలో మంచుతో కూడిన రహదారి\n",
      "🌍 Malayalam 🇮🇳: പർവതങ്ങളിലെ മഞ്ഞുവീഴ്ചയുള്ള റോഡ്\n",
      "🌍 Hindi 🇮🇳: पहाड़ों में एक बर्फीली सड़क\n",
      "--------------------------------------------------\n",
      "🖼️ five.jpg\n",
      "🌍 English: a bird sitting on a wall in the rain\n",
      "🌍 Tamil 🇮🇳: மழையில் ஒரு சுவரில் அமர்ந்திருக்கும் பறவை\n",
      "🌍 Kannada 🇮🇳: ಮಳೆಯಲ್ಲಿ ಗೋಡೆಯ ಮೇಲೆ ಕುಳಿತಿದ್ದ ಹಕ್ಕಿ\n",
      "🌍 Telugu 🇮🇳: వర్షంలో గోడపై కూర్చున్న పక్షి\n",
      "🌍 Malayalam 🇮🇳: മഴയിൽ ഒരു മതിൽ ഇരിക്കുന്ന പക്ഷി\n",
      "🌍 Hindi 🇮🇳: बारिश में एक दीवार पर बैठा एक पक्षी\n",
      "--------------------------------------------------\n",
      "🖼️ four.jpg\n",
      "🌍 English: a couple sitting on a bench looking out at the ocean\n",
      "🌍 Tamil 🇮🇳: ஒரு பெஞ்சில் உட்கார்ந்திருக்கும் ஒரு ஜோடி கடலுக்கு வெளியே\n",
      "🌍 Kannada 🇮🇳: ದಂಪತಿಗಳು ಸಾಗರವನ್ನು ನೋಡುತ್ತಿರುವ ಬೆಂಚ್ ಮೇಲೆ ಕುಳಿತಿದ್ದಾರೆ\n",
      "🌍 Telugu 🇮🇳: ఒక జంట సముద్రం వైపు చూస్తున్న బెంచ్ మీద కూర్చున్నారు\n",
      "🌍 Malayalam 🇮🇳: സമുദ്രത്തിൽ നോക്കുമ്പോൾ ഒരു ബെഞ്ചിൽ ഇരിക്കുന്ന ദമ്പതികൾ\n",
      "🌍 Hindi 🇮🇳: एक बेंच पर बैठे एक जोड़े समुद्र में बाहर देख रहे हैं\n",
      "--------------------------------------------------\n",
      "🖼️ nine.jpg\n",
      "🌍 English: a man walking up a path in the mountains\n",
      "🌍 Tamil 🇮🇳: மலைகளில் ஒரு பாதையில் நடந்து செல்லும் ஒரு மனிதன்\n",
      "🌍 Kannada 🇮🇳: ಪರ್ವತಗಳಲ್ಲಿ ಒಂದು ಹಾದಿಯಲ್ಲಿ ನಡೆಯುವ ವ್ಯಕ್ತಿ\n",
      "🌍 Telugu 🇮🇳: ఒక వ్యక్తి పర్వతాలలో ఒక మార్గం పైకి నడుస్తున్నాడు\n",
      "🌍 Malayalam 🇮🇳: ഒരു മനുഷ്യൻ പർവതങ്ങളിൽ ഒരു പാതയിലൂടെ നടക്കുന്നു\n",
      "🌍 Hindi 🇮🇳: एक आदमी पहाड़ों में एक रास्ता चल रहा है\n",
      "--------------------------------------------------\n",
      "🖼️ one.jpg\n",
      "🌍 English: a bird perched on a tree stump\n",
      "🌍 Tamil 🇮🇳: ஒரு மரத்தின் ஸ்டம்பில் ஒரு பறவை\n",
      "🌍 Kannada 🇮🇳: ಮರದ ಸ್ಟಂಪ್ ಮೇಲೆ ಒಂದು ಹಕ್ಕಿ\n",
      "🌍 Telugu 🇮🇳: చెట్టు స్టంప్ మీద ఒక పక్షి\n",
      "🌍 Malayalam 🇮🇳: ഒരു മരത്തിൽ ഒരു പക്ഷി\n",
      "🌍 Hindi 🇮🇳: एक पक्षी एक पेड़ के स्टंप पर बैठ गया\n",
      "--------------------------------------------------\n",
      "🖼️ seven.jpg\n",
      "🌍 English: a bright orange sunset over the ocean\n",
      "🌍 Tamil 🇮🇳: கடலுக்கு மேல் ஒரு பிரகாசமான ஆரஞ்சு சூரிய அஸ்தமனம்\n",
      "🌍 Kannada 🇮🇳: ಸಮುದ್ರದ ಮೇಲೆ ಪ್ರಕಾಶಮಾನವಾದ ಕಿತ್ತಳೆ ಸೂರ್ಯಾಸ್ತ\n",
      "🌍 Telugu 🇮🇳: సముద్రం మీద ప్రకాశవంతమైన నారింజ సూర్యాస్తమయం\n",
      "🌍 Malayalam 🇮🇳: സമുദ്രത്തിന് മുകളിൽ ഒരു തിളക്കമുള്ള ഓറഞ്ച് സൂര്യാസ്തമയം\n",
      "🌍 Hindi 🇮🇳: समुद्र के ऊपर एक उज्ज्वल नारंगी सूर्यास्त\n",
      "--------------------------------------------------\n",
      "🖼️ six.jpg\n",
      "🌍 English: a woman sitting in a chair in a living room\n",
      "🌍 Tamil 🇮🇳: ஒரு வாழ்க்கை அறையில் நாற்காலியில் அமர்ந்திருக்கும் ஒரு பெண்\n",
      "🌍 Kannada 🇮🇳: ವಾಸದ ಕೋಣೆಯಲ್ಲಿ ಕುರ್ಚಿಯಲ್ಲಿ ಕುಳಿತ ಮಹಿಳೆ\n",
      "🌍 Telugu 🇮🇳: ఒక మహిళ గదిలో కుర్చీలో కూర్చుని\n",
      "🌍 Malayalam 🇮🇳: ഒരു സ്വീകരണമുറിയിൽ ഒരു വനിത ഒരു സ്ത്രീ\n",
      "🌍 Hindi 🇮🇳: लिविंग रूम में एक कुर्सी पर बैठी एक महिला\n",
      "--------------------------------------------------\n",
      "🖼️ ten.jpg\n",
      "🌍 English: a cup with a flower in it\n",
      "🌍 Tamil 🇮🇳: அதில் ஒரு பூவுடன் ஒரு கப்\n",
      "🌍 Kannada 🇮🇳: ಅದರಲ್ಲಿ ಹೂವಿನೊಂದಿಗೆ ಒಂದು ಕಪ್\n",
      "🌍 Telugu 🇮🇳: దానిలో ఒక పువ్వుతో ఒక కప్పు\n",
      "🌍 Malayalam 🇮🇳: അതിൽ ഒരു പുഷ്പമുള്ള ഒരു കപ്പ്\n",
      "🌍 Hindi 🇮🇳: इसमें एक फूल के साथ एक कप\n",
      "--------------------------------------------------\n",
      "🖼️ three.jpg\n",
      "🌍 English: two swans swimming in the water\n",
      "🌍 Tamil 🇮🇳: இரண்டு ஸ்வான்ஸ் தண்ணீரில் நீந்துகிறது\n",
      "🌍 Kannada 🇮🇳: ಎರಡು ಹಂಸಗಳು ನೀರಿನಲ್ಲಿ ಈಜುತ್ತಿವೆ\n",
      "🌍 Telugu 🇮🇳: రెండు హంసలు నీటిలో ఈత కొడుతున్నాయి\n",
      "🌍 Malayalam 🇮🇳: വെള്ളത്തിൽ നീന്തൽ\n",
      "🌍 Hindi 🇮🇳: दो हंस पानी में तैरते हुए\n",
      "--------------------------------------------------\n",
      "\n",
      "✅ Captions saved in **captions_combined.txt**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "from googletrans import Translator\n",
    "\n",
    "# Load BLIP Model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# Initialize Translator\n",
    "translator = Translator()\n",
    "\n",
    "# Define paths\n",
    "image_folder = \"E:\\\\images\"   # Folder with images\n",
    "video_path = \"E:\\\\videos.mp4\"  # Path to video\n",
    "frames_folder = \"E:\\\\videos\\\\frames\"\n",
    "output_file = \"captions_combined.txt\"\n",
    "\n",
    "# Ensure folders exist\n",
    "os.makedirs(frames_folder, exist_ok=True)\n",
    "\n",
    "# Function to generate captions for an image\n",
    "def generate_caption(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return caption\n",
    "\n",
    "# Function to translate captions into multiple languages\n",
    "def translate_caption(caption):\n",
    "    languages = {\n",
    "        \"ta\": \"Tamil 🇮🇳\", \"kn\": \"Kannada 🇮🇳\", \"te\": \"Telugu 🇮🇳\", \n",
    "        \"ml\": \"Malayalam 🇮🇳\", \"hi\": \"Hindi 🇮🇳\"\n",
    "    }\n",
    "    translated_captions = { \"English\": caption }\n",
    "    \n",
    "    for lang_code, lang_name in languages.items():\n",
    "        translated_captions[lang_name] = translator.translate(caption, dest=lang_code).text\n",
    "    \n",
    "    return translated_captions\n",
    "\n",
    "# Store captions\n",
    "captions_list = []\n",
    "\n",
    "### **📸 Process Images**\n",
    "for image_name in os.listdir(image_folder):\n",
    "    if image_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        caption = generate_caption(image_path)\n",
    "        translated_captions = translate_caption(caption)\n",
    "\n",
    "        # Save captions\n",
    "        captions_list.append(f\"🖼️ {image_name}\")\n",
    "        for lang, trans_caption in translated_captions.items():\n",
    "            captions_list.append(f\"🌍 {lang}: {trans_caption}\")\n",
    "        captions_list.append(\"-\" * 50)\n",
    "\n",
    "### **🎥 Process Video Frames**\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))  # Get FPS\n",
    "frame_interval = 5 * fps  # Capture every 5 seconds\n",
    "\n",
    "frame_count = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Extract frame at intervals\n",
    "    if frame_count % frame_interval == 0:\n",
    "        frame_filename = os.path.join(frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "        cv2.imwrite(frame_filename, frame)\n",
    "\n",
    "        caption = generate_caption(frame_filename)\n",
    "        translated_captions = translate_caption(caption)\n",
    "\n",
    "        # Convert frame timestamp\n",
    "        time_stamp = frame_count // fps\n",
    "        minutes, seconds = divmod(time_stamp, 60)\n",
    "        time_format = f\"{minutes:02d}:{seconds:02d}\"\n",
    "\n",
    "        # Save captions\n",
    "        captions_list.append(f\"🕒 [{time_format}]\")\n",
    "        for lang, trans_caption in translated_captions.items():\n",
    "            captions_list.append(f\"🌍 {lang}: {trans_caption}\")\n",
    "        captions_list.append(\"-\" * 50)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "# Save captions to file and print in terminal\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for caption in captions_list:\n",
    "        print(caption)  # ✅ Print in terminal\n",
    "        f.write(caption + \"\\n\")\n",
    "\n",
    "print(f\"\\n✅ Captions saved in **{output_file}**\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6017eeb5-d00d-4cf9-abff-754c758ee97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select input type:\n",
      "1️⃣ Images\n",
      "2️⃣ Videos\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your choice (1/2):  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Select a language:\n",
      "1. English\n",
      "2. Tamil\n",
      "3. Kannada\n",
      "4. Telugu\n",
      "5. Malayalam\n",
      "6. Hindi\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your language choice:  1,3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Processing Video...\n",
      "\n",
      "\n",
      "✅ Captions saved in **captions_combined.txt**\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "import time\n",
    "\n",
    "# Load BLIP model\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "\n",
    "# User selects content type\n",
    "print(\"\\nSelect input type:\")\n",
    "print(\"1️⃣ Images\")\n",
    "print(\"2️⃣ Videos\")\n",
    "choice = input(\"Enter your choice (1/2): \")\n",
    "\n",
    "# User selects language\n",
    "languages = {\n",
    "    \"1\": \"English\",\n",
    "    \"2\": \"Tamil\",\n",
    "    \"3\": \"Kannada\",\n",
    "    \"4\": \"Telugu\",\n",
    "    \"5\": \"Malayalam\",\n",
    "    \"6\": \"Hindi\",\n",
    "}\n",
    "print(\"\\nSelect a language:\")\n",
    "for key, lang in languages.items():\n",
    "    print(f\"{key}. {lang}\")\n",
    "\n",
    "lang_choice = input(\"\\nEnter your language choice: \")\n",
    "\n",
    "# Set up paths\n",
    "image_folder = \"images\"\n",
    "video_folder = \"videos\"\n",
    "frames_folder = \"frames\"\n",
    "output_file = \"captions_combined.txt\"\n",
    "os.makedirs(frames_folder, exist_ok=True)  # Ensure frames folder exists\n",
    "\n",
    "captions_list = []\n",
    "\n",
    "# Process images\n",
    "if choice == \"1\":\n",
    "    print(\"\\n🔹 Processing Images...\\n\")\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        if image_name.lower().endswith((\".jpg\", \".png\", \".jpeg\")):\n",
    "            image_path = os.path.join(image_folder, image_name)\n",
    "            try:\n",
    "                image = Image.open(image_path).convert(\"RGB\")\n",
    "                inputs = processor(image, return_tensors=\"pt\")\n",
    "                output = model.generate(**inputs)\n",
    "                caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "                captions_list.append(f\"{image_name}: {caption}\")\n",
    "                print(f\"✅ {image_name}: {caption}\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error processing {image_name}: {e}\")\n",
    "\n",
    "# Process videos (Extract frames every 5 seconds)\n",
    "elif choice == \"2\":\n",
    "    print(\"\\n🔹 Processing Video...\\n\")\n",
    "    for video_name in os.listdir(video_folder):\n",
    "        if video_name.lower().endswith((\".mp4\", \".avi\", \".mov\", \".mkv\")):\n",
    "            video_path = os.path.join(video_folder, video_name)\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "            fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "            frame_interval = 5 * fps  # Capture every 5 seconds\n",
    "\n",
    "            frame_count = 0\n",
    "            while cap.isOpened():\n",
    "                ret, frame = cap.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                if frame_count % frame_interval == 0:\n",
    "                    frame_filename = os.path.join(frames_folder, f\"frame_{frame_count}.jpg\")\n",
    "                    cv2.imwrite(frame_filename, frame)\n",
    "                    print(f\"📸 Extracted Frame: {frame_filename}\")\n",
    "\n",
    "                    # Generate caption for frame\n",
    "                    try:\n",
    "                        image = Image.open(frame_filename).convert(\"RGB\")\n",
    "                        inputs = processor(image, return_tensors=\"pt\")\n",
    "                        output = model.generate(**inputs)\n",
    "                        caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "                        captions_list.append(f\"{frame_filename}: {caption}\")\n",
    "                        print(f\"✅ Caption: {caption}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"❌ Error processing {frame_filename}: {e}\")\n",
    "\n",
    "                frame_count += 1\n",
    "            cap.release()\n",
    "\n",
    "# Save captions\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(captions_list))\n",
    "\n",
    "print(f\"\\n✅ Captions saved in **{output_file}**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a9541b81-e7f4-465e-8543-ab5b6ae5a33b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BLIP model...\n",
      "Model loaded successfully!\n",
      "✅ Found images folder: E:\\images\n",
      "📂 Found 9 images: ['eight.jpg', 'five.jpg', 'four.jpg', 'nine.jpg', 'one.jpg', 'seven.jpg', 'six.jpg', 'ten.jpg', 'three.jpg']\n",
      "🖼 Processing image: E:\\images\\eight.jpg\n",
      "✅ Caption: a snowy road in the mountains\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# Load model\n",
    "print(\"Loading BLIP model...\")\n",
    "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Check images folder\n",
    "image_folder = \"E:\\\\images\"\n",
    "if not os.path.exists(image_folder):\n",
    "    print(f\"Error: Folder '{image_folder}' not found!\")\n",
    "else:\n",
    "    print(f\"✅ Found images folder: {image_folder}\")\n",
    "\n",
    "# List available images\n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith((\".jpg\", \".png\", \".jpeg\"))]\n",
    "print(f\"📂 Found {len(image_files)} images: {image_files}\")\n",
    "\n",
    "# Process first image for testing\n",
    "if image_files:\n",
    "    image_path = os.path.join(image_folder, image_files[0])\n",
    "    print(f\"🖼 Processing image: {image_path}\")\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "    output = model.generate(**inputs)\n",
    "    caption = processor.decode(output[0], skip_special_tokens=True)\n",
    "    print(f\"✅ Caption: {caption}\")\n",
    "else:\n",
    "    print(\"❌ No images found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5e07763b-789c-4986-91a0-808f4b6e02ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.ipynb_checkpoints', 'Captures', 'desktop.ini', 'practice1.ipynb', 'Screen Recordings', 'Shortcut to Videos (OneDrive - Personal).lnk']\n",
      "Error: Cannot open video file!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"videos\"))  # Should list your video files\n",
    "import cv2\n",
    "cap = cv2.VideoCapture(\"E:\\\\videos/sample.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Cannot open video file!\")\n",
    "else:\n",
    "    print(\"Video opened successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24cd79d0-bb8d-4541-a67a-64f2b17b46a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
